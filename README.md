<h1 align="center">
  CHeaT&nbsp;ğŸ›¡ï¸â€” Cloak â€¢ Honey â€¢ Trap
</h1>

<p align="center">
  <a href="#-tool-quick-start">Quick&nbsp;Start</a> â€¢
  <a href="#-repository-layout">Repo&nbsp;Layout</a> â€¢
  <a href="#-paper">Paper</a> â€¢
  <a href="#-datasets">Datasets</a> â€¢
  <a href="#%EF%B8%8F-ctf-machines">CTF&nbspMachines</a> â€¢
  <a href="#-token-landmines">Token&nbsp;Landmines</a> â€¢
  <a href="#-demo-notebook">Demo&nbsp;Notebook</a> â€¢
  <a href="#-citation">Citation</a>
</p>

---

## ğŸŒŸ Project Overview
CHeaT (Cloakâ€“Honeyâ€“Trap) is a CLI-based tool that **defends networks against autonomous LLM-powered pentesting agents** by planting string-based payloads into network assets. These paylaods are designed to distrupt and detect LLM-based pentesting agents. "

Defeneses:
1. **Cloaking** sensitive data with misdirection  
2. Planting **Honey** tokens to detect & fingerprint LLM agents  
3. Setting **Traps** that stall or crash abusive agents  

For more information on how it works, please see our USENIX Security â€™25 publication:

``
Daniel Ayzenshteyn, Weiss, Roy, and Yisroel Mirsky. "Cloak, Honey, Trap: Proactive Defenses Against LLM Agents" 34rth USENIX Security Symposium (USENIX Security 25). 2025.â€
``

---

## ğŸš€ Tool Quick Start

> **TL;DR**

```bash
# clone repo & enter tool folder
git clone https://github.com/Daniel-Ayz/CHeaT.git
cd CHeaT

# optional: create venv
python3 -m venv .venv && source .venv/bin/activate

# install (pure-stdlib -> nothing to pull)
pip install -e .

# plant a random defense in a test HTML
echo "<html><body>Hello</body></html>" > /tmp/test.html
cheat --action plant --details '{
  "assettype": "web_file",
  "file_path": "/tmp/test.html",
  "technique": "random",
}'
````

| Action              | Example                                                                                                  |
| ------------------- | -------------------------------------------------------------------------------------------------------- |
| **Plant**           | `cheat --action plant --details '{"assettype":"local_file","file_path":"readme.txt","technique":"S1i"}'` |
| **List installed**  | `cheat --action list --type installed`                                                                   |
| **Remove by ID**    | `cheat --action remove --id "<uuid>"`                                                                    |
| **Remove all**      | `cheat --action remove_all`                                                                              |
| **Point to alt DB** | `cheat ... --database /path/to/db`                                                                       |

See [`cheat/README.md`](cheat/README.md) for full CLI docs.

---

## ğŸ“‚ Repository Layout

```
CHeaT/
â”œâ”€ cheat/               â† Python package (tool)
â”‚   â”œâ”€ database/        â† default JSON techniques & templates
â”‚   â””â”€ ...
â”œâ”€ datasets/            â† datasets used in the paper evaluations
â”œâ”€ ctf-machines/        â† ready-to-run vulnerable VMs
â”œâ”€ token-landmines/     â† unicode landmines
â”œâ”€ demo-notebook/       â† Jupyter walkthrough & sandbox
â”œâ”€ Whitepaper.pdf       â† full academic paper
â””â”€ README.md            â† you are here
```

---

## ğŸ“œ Paper

The full methodology, threat model, and evaluation are in **â€œCloak, Honey, Trap: Proactive Defenses Against LLM Agents.â€**
Read the PDF or check the arXiv link in the paper header for details.
Key numbers:

* 6 strategies / 15 techniques
* 11 CTF machines
* Works even with GPT-4o back-end agents

---

## ğŸ“Š Datasets

Directory **`datasets/`** collects:

```
datasets/
â”œâ”€ dataset_main.json
â”œâ”€ dataset_boosted_with_pi.json
â”œâ”€ dataset_unicode_honeytokens.json
â””â”€payloads/
  â”œâ”€ payloads.json
  â””â”€ payloads_boosted_with_prompt_injection.json
````

* **`payloads.json`** â€“ the framed payloads constructed in the paper.  
* **`payloads_boosted_with_prompt_injection.json`** â€“ payloads that are *boosted* with a prompt-injection wrapper.  
* **`dataset_main.json`** â€“ embeds the framed payloads at multiple target data points and system prompts (uses `payloads.json`).  
* **`dataset_boosted_with_pi.json`** â€“ identical structure but built from the boosted payloads.
* **`dataset_unicode_honeytokens`** â€“ dataset used to evaluate the honeytokens (Set A and Set B in T3.2)
  
---

## ğŸ–¥ï¸ CTF Machines

11 Ready-to-import OVA VMs used in the paperâ€™s evaluation:

`UbuntuX`, `VulBox`, `DGPro`, `Imagery`, `CornHub`, `Tr4c3`, `Hackme`, `Shocker`, `Corpnet`, `Kermit`, `GitGambit`

* Each folder contains the machines image (.ova) and a walkthrough solution.

---

## ğŸ’£ Token Landmines

Detect and evaluate â€œlandmine tokensâ€â€”rare tokens that cause LLMs to produce gibberish or hallucinations.

---

## ğŸ“’ Demo Notebook

Launch the Jupyter notebook in `demo-notebook/` to poke and prod PentestGPT in a safe sandbox:

- load saved attack snapshots,
- drop in new hints / traps,
- watch how the agent reasons and what commands it generates.

---

## ğŸ“„ License

MIT Â© 2025 Ayzenshteyn â€¢ Weiss â€¢ Mirsky

---

## ğŸ¤ Citation

For citations:

```bibtex
@inproceedings{Ayzenshteyn2025CHeaT,
  title={{CHeaT}: Cloak, Honey, Trap â€“ Proactive Defenses Against LLM Agents},
  author={Daniel Ayzenshteyn and Roy Weiss and Yisroel Mirsky},
  booktitle={USENIX Security},
  year={2025}
}
```

Happy trapping! ğŸ•¸ï¸
